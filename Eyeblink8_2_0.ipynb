{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8V1cudq41cOp2rTy4aNeQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gapilesh/BlinkKey_FinalProject/blob/main/Eyeblink8_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Mount Google Drive"
      ],
      "metadata": {
        "id": "hIFin0srDUR0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brEYMjTUAEFg",
        "outputId": "81491bbb-3af6-4364-d5ff-8ae53e6b6498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Extract Dataset**"
      ],
      "metadata": {
        "id": "UYT9PdJ6DZX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Dataset/Eyeblink/eyeblink8.zip'\n",
        "extract_path = '/content/drive/MyDrive/Dataset/Eyeblink'\n",
        "\n",
        "if not os.path.exists(os.path.join(extract_path, 'eyeblink8')):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Dataset unzipped successfully!\")\n",
        "else:\n",
        "    print(\"Dataset already exists, skipping extraction.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upXS8Td8C5VT",
        "outputId": "30832a24-c299-4a37-a18b-87eee4382a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset unzipped successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Check Dataset Structure**"
      ],
      "metadata": {
        "id": "Tj9sfzWDDcoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/Dataset/Eyeblink/eyeblink8'\n",
        "folders = sorted(os.listdir(dataset_path))\n",
        "print(\"Folders in the dataset:\", folders)\n",
        "\n",
        "sample_folder = os.path.join(dataset_path, '1')\n",
        "sample_files = os.listdir(sample_folder)\n",
        "print(\"Files in folder '1':\", sample_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW4xznQuDNMk",
        "outputId": "e896b280-8b24-4619-8267-f14342b2e1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders in the dataset: ['1', '10', '11', '2', '3', '4', '8', '9']\n",
            "Files in folder '1': ['26122013_223310_cam.avi', '26122013_223310_cam.tag', '26122013_223310_cam.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Install & Import OpenCV**"
      ],
      "metadata": {
        "id": "sGlvrWB6DfvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQqmWPiuDQk8",
        "outputId": "7bd23166-f5d5-478c-e29d-ade85c15d9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Extract Frames Efficiently**"
      ],
      "metadata": {
        "id": "iKhh9vwBDjEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(video_path, output_folder, frame_skip=10, frame_limit=500):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    extracted_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or extracted_count >= frame_limit:\n",
        "            break\n",
        "\n",
        "        if frame_count % frame_skip == 0:  # Skip frames to reduce memory load\n",
        "            frame_path = os.path.join(output_folder, f\"frame_{extracted_count:04d}.jpg\")\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "            extracted_count += 1\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Extracted {extracted_count} frames from {video_path}\")\n",
        "\n",
        "video_path = os.path.join(dataset_path, '1', '1.mp4')\n",
        "output_folder = '/content/drive/MyDrive/Dataset/Eyeblink/frames/1'\n",
        "extract_frames(video_path, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gunn_vVgDiSz",
        "outputId": "88c34003-3198-4646-c855-ae10beca693f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 0 frames from /content/drive/MyDrive/Dataset/Eyeblink/eyeblink8/1/1.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Parse Annotations**"
      ],
      "metadata": {
        "id": "-Jl6GOYPEEZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_annotations(annotation_path):\n",
        "    with open(annotation_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    timestamps = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) == 2:\n",
        "            timestamps.append(float(parts[1]))  # Assuming second value is timestamp\n",
        "\n",
        "    return timestamps\n",
        "\n",
        "annotation_path = os.path.join(dataset_path, '1', '1.txt')\n",
        "timestamps = parse_annotations(annotation_path)\n",
        "print(\"Sample timestamps:\", timestamps[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "8d2-n_mOEGAT",
        "outputId": "b9eab303-ee3d-4bcc-ede5-892b1f2fd175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Dataset/Eyeblink/eyeblink8/1/1.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a0b1b5ad82d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mannotation_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtimestamps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample timestamps:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-a0b1b5ad82d5>\u001b[0m in \u001b[0;36mparse_annotations\u001b[0;34m(annotation_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtimestamps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dataset/Eyeblink/eyeblink8/1/1.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Prepare Frames & Labels**"
      ],
      "metadata": {
        "id": "YSwH5hizFdWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_frames_and_labels(folder, frame_limit=500):\n",
        "    frames, labels = [], []\n",
        "    annotation_path = os.path.join(folder, '1.txt')\n",
        "\n",
        "    if not os.path.exists(annotation_path):\n",
        "        print(\"Annotation file missing for:\", folder)\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    timestamps = parse_annotations(annotation_path)\n",
        "\n",
        "    for i in range(min(len(timestamps), frame_limit)):\n",
        "        frame_path = os.path.join(folder, f\"frame_{i:04d}.jpg\")\n",
        "        if os.path.exists(frame_path):\n",
        "            frame = cv2.imread(frame_path)\n",
        "            frame = cv2.resize(frame, (224, 224)) / 255.0  # Normalize\n",
        "            frames.append(frame)\n",
        "            labels.append(1 if timestamps[i] > 0 else 0)  # Example thresholding\n",
        "\n",
        "    return np.array(frames), np.array(labels)\n",
        "\n",
        "frames, labels = load_frames_and_labels('/content/drive/MyDrive/Dataset/Eyeblink/frames/1')\n",
        "print(\"Frames shape:\", frames.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n"
      ],
      "metadata": {
        "id": "miL3eef2FjPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Define a Lightweight Model**"
      ],
      "metadata": {
        "id": "Cfis6_QYFnpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed\n",
        "\n",
        "model = Sequential([\n",
        "    TimeDistributed(Conv2D(16, (3,3), activation='relu'), input_shape=(None, 224, 224, 3)),\n",
        "    TimeDistributed(MaxPooling2D((2,2))),\n",
        "    TimeDistributed(Flatten()),\n",
        "    LSTM(32, return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "TdCRpNhoFqOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Train Model in Small Batches**"
      ],
      "metadata": {
        "id": "SH-2uDHdFrpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100  # Smaller batch size to fit in RAM\n",
        "frames = np.expand_dims(frames, axis=0)  # Add batch dimension\n",
        "labels = np.expand_dims(labels, axis=0)\n",
        "\n",
        "for epoch in range(3):  # Reduce epochs to avoid crashes\n",
        "    print(f\"Training Epoch {epoch + 1}...\")\n",
        "    model.fit(frames, labels, epochs=1, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Save model\n",
        "model.save('/content/drive/MyDrive/eyeblink_model.h5')\n"
      ],
      "metadata": {
        "id": "EFX8SsBTFtoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Evaluate Model**"
      ],
      "metadata": {
        "id": "UhGzsFi3FvDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(frames, labels)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "r2oOvuEgFxc7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}